{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boatboyrob27/Computational-Media/blob/main/Train_a_GPT_2_Text_Generating_Model_w_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free\n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: October 17th, 2021*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23cb46e-9a45-4076-851d-235a702dfbfd"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d008af-a3ed-4ac6-a5a7-48eaab4572cb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  8 00:17:56 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first.\n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af21dae-f98a-4a9a-d4bc-a6da8b2bee19"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 4.38Git/s]                                                     \n",
            "Fetching encoder.json: 1.05Mit [00:01, 585kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 4.15Git/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:52, 9.47Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 1.46Git/s]                                               \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 879kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 873kit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82e966d-7f76-4584-a712-e816008d74c4"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"shakespeare.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "# gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "ab76f552-8244-4ae3-a791-8cd6906be960"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=\"shakespeare.txt\",\n",
        "              model_name='124M',\n",
        "              steps=200,\n",
        "              restore_from='latest',\n",
        "              overwrite=True,\n",
        "              run_name='run1',\n",
        "              print_every=25,\n",
        "              sample_every=50,\n",
        "              save_every=100\n",
        "              )"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-7ba8dbf04b92>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m gpt2.finetune(sess,\n\u001b[0m\u001b[1;32m      4\u001b[0m               \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shakespeare.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'124M'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     loss = tf.reduce_mean(\n\u001b[1;32m    200\u001b[0m         input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         wpe = tf.compat.v1.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n\u001b[0m\u001b[1;32m    189\u001b[0m                              initializer=tf.compat.v1.random_normal_initializer(stddev=0.01))\n\u001b[1;32m    190\u001b[0m         wte = tf.compat.v1.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1628\u001b[0m                  \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariableSynchronization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m                  aggregation=VariableAggregation.NONE):\n\u001b[0;32m-> 1630\u001b[0;31m   return get_variable_scope().get_variable(\n\u001b[0m\u001b[1;32m   1631\u001b[0m       \u001b[0m_get_default_variable_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       return var_store.get_variable(\n\u001b[0m\u001b[1;32m   1341\u001b[0m           \u001b[0mfull_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    583\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m       return _true_getter(\n\u001b[0m\u001b[1;32m    586\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \"name was already created with partitioning?\" % name)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m       return self._get_single_variable(\n\u001b[0m\u001b[1;32m    539\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;31m# ResourceVariables don't have an op associated with so no traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;31m# Throw away internal tf entries and only take a few lines. In some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96749880-ef97-490e-c058-c3829ee3db20"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58567ac-7d29-428a-c969-7db4792a1b3d"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1', length=200, nsamples=10, prefix=\"\"\"ROMEO.\n",
        "He jests at scars that never felt a wound.\n",
        "\n",
        " Juliet appears above at a window.\n",
        "\n",
        "But soft, what light through yonder window breaks?\n",
        "It is the east, and Juliet is the sun!\n",
        "Arise fair sun and kill the envious moon,\n",
        "Who is already sick and pale with grief,\n",
        "That thou her maid art far more fair than she.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "Be we not gentle, I wonder at thee!\n",
            "\n",
            "MOTHER.\n",
            "Pray thee, be so at liberty, and be as fair as I\n",
            "Be fair as thou art fair.\n",
            "\n",
            "CHIRON.\n",
            "How shall I know it?\n",
            "\n",
            "MOTHER.\n",
            "I know not what I am, but I am but fair.\n",
            "\n",
            "CHIRON.\n",
            "What art thou then?\n",
            "\n",
            "MOTHER.\n",
            "What art thou?\n",
            "\n",
            "CHIRON.\n",
            "What art thou then?\n",
            "\n",
            "MOTHER.\n",
            "The very title of this lady, that is,\n",
            "The first-born of a fair and just mother,\n",
            "That now is a queen and queen-maid.\n",
            "\n",
            "CHIRON.\n",
            "What is her name?\n",
            "\n",
            "MOTHER.\n",
            "Clarence, I warrant you.\n",
            "\n",
            "CHIRON.\n",
            "Clarence is but a very well-bred maid.\n",
            "\n",
            "MOTHER.\n",
            "She is not a very\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "\n",
            "[_Exeunt._]\n",
            "\n",
            "SCENE III. The city of Gremio.\n",
            "\n",
            "Enter two Attendants.\n",
            "\n",
            "ASSISTANT.\n",
            "I’ll show you the curtains, the curtain that I will wrap.\n",
            "\n",
            "FIRST ATTENDANT.\n",
            "It shall be done, sir.\n",
            "\n",
            "SECOND ATTENDANT.\n",
            "Well, sir, I will present you the curtains.\n",
            "\n",
            "Enter Gremio.\n",
            "\n",
            "GREEMIO.\n",
            "Gentlewoman, by and by we bring you a letter.\n",
            "\n",
            "SECOND LECTOR.\n",
            "Your lord says that a very fine duke’s wife,\n",
            "Who, upon oath, was a Lady of Gremio,\n",
            "Had been appointed for three years, and was thus murdered,\n",
            "And this she was by her husband.\n",
            "\n",
            "GENTLEMAN.\n",
            "You are not a gentleman, are you?\n",
            "\n",
            "FIRST LORD.\n",
            "A lady,\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "O, look thou, fair cousin, look you,\n",
            "That comes in the best of these fair days,\n",
            "Where but fair looks will you, fair am I!\n",
            "O, look you, fair cousin, look you,\n",
            "That comes in the best of these fair days,\n",
            "Where but fair looks will you, fair am I!\n",
            "O, look you, fair cousin, look you,\n",
            "That comes in the best of these fair days,\n",
            "Where but fair looks will you, fair am I!\n",
            "\n",
            " Enter Crab.\n",
            "\n",
            "CUBIN.\n",
            "O, my lord, I am sure, my lord,\n",
            "Have you seen this black-and-white ball?\n",
            "\n",
            "WARWICK.\n",
            "No one in the house, my lord.\n",
            "\n",
            "CUBIN.\n",
            "But you have seen some other stuff?\n",
            "\n",
            "WARWICK.\n",
            "Well, my lord, you have seen some old nose,\n",
            "Some kind of ice-coated cock, some\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "\n",
            "[_Exeunt._]\n",
            "\n",
            "SCENE III. A Room in the Palace\n",
            "\n",
            "Enter Portia, Queen, Florence and the Duke of Gloucester.\n",
            "\n",
            "QUEEN.\n",
            "My lord, my lords, I am sorry to see you.\n",
            "Sirrah, this ye have heard of me?\n",
            "\n",
            "PORTIA.\n",
            "The Duke of Gloucester, so my lord,\n",
            "That it were but but my notice to you,\n",
            "And all your hope to have a better word with you,\n",
            "Is lost. I was a villain in my youth.\n",
            "\n",
            "QUEEN.\n",
            "These matter, Duke of Gloucester, are very grievous.\n",
            "The worst part of my life is sobered;\n",
            "But I have every warrant to do you good.\n",
            "\n",
            "PORTIA.\n",
            "Sir, I am not so sure of it.\n",
            "But since the day I saw you, my lord,\n",
            "You have been a villain, and I believe it,\n",
            "\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "\n",
            "HIPPOLY.\n",
            "Farewell, fair lady, and stay at home.\n",
            "\n",
            " [_Exit._]\n",
            "\n",
            "SCENE IV. The same. A Room in the Palace\n",
            "\n",
            "Enter Nurse and Clown.\n",
            "\n",
            "NURSE.\n",
            "So I have heard,\n",
            "That every thing in the world,\n",
            "And every matter in the world,\n",
            "Wishes me my home, where I will be\n",
            "And free to do what I wish.\n",
            "\n",
            "CLOWN.\n",
            "I thank you, Nurse, for yeare well.\n",
            "\n",
            "NURSE.\n",
            "Yes, and well indeed, for so I have heard.\n",
            "O, they are as fair as the sky\n",
            "That the sky to save our lives drops upon us!\n",
            "\n",
            "CLOWN.\n",
            "O, they are as fair as the moon to save our lives!\n",
            "\n",
            "NURSE.\n",
            "And so I shall be.\n",
            "\n",
            "CLOWN.\n",
            "O, here comes your Nurse, my dear\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "So come to her, come to her, you see;\n",
            "Come, come, come, come, you see.\n",
            "\n",
            " [_Exeunt._]\n",
            "\n",
            "SCENE II. The Plains of Capulet\n",
            "\n",
            "\n",
            "ACT I\n",
            "\n",
            "SCENE I. The Plains of Capulet\n",
            "\n",
            "ACT II\n",
            "SCENE I. The Plains of Capulet\n",
            "\n",
            "ACT III\n",
            "SCENE I. The Plains of Capulet\n",
            "\n",
            "\n",
            "Music\n",
            "\n",
            "SCENE II. The Plains of Capulet\n",
            "\n",
            "\n",
            "ACT I\n",
            "SCENE I. The Plains of Capulet\n",
            "\n",
            "ACT II\n",
            "SCENE I. The Plains of Capulet\n",
            "ACT III\n",
            "SCENE I. The Plains of Capulet\n",
            "SCENE II. The Plains of Capulet\n",
            "\n",
            "\n",
            "ACT I\n",
            "SCENE I. The Plains of Capulet\n",
            "ACT II\n",
            "SCENE I. The Plains of Capulet\n",
            "ACT III\n",
            "SCENE I. The Plains of Capulet\n",
            "ACT IV\n",
            "SCENE I. The\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "\n",
            "PANDARRA.\n",
            "Is not the golden sun too rare?\n",
            "\n",
            "HIPPOLY.\n",
            "It is too rare, unless he be a king.\n",
            "\n",
            "PANDARRA.\n",
            "If he is a king, he is a sun;\n",
            "And yet, if he be a sun, he is a moon;\n",
            "And yet, if he be a moon, he is a sun;\n",
            "And yet, if he be a sun, he is a moon,\n",
            "And yet, if he be a moon, he is a sun;\n",
            "And yet, if he are a moon, he is a sun.\n",
            "\n",
            "HIPPOLY.\n",
            "Now, if a man be a sun, he is a moon;\n",
            "And yet, if a moon, he is a sun.\n",
            "\n",
            "PANDARRA.\n",
            "And yet, if a man be a sun, he is a moon;\n",
            "And yet, if a moon, he is a sun.\n",
            "\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "\n",
            "[_Exeunt._]\n",
            "\n",
            "SCENE II. The same. A Room in the Palace.\n",
            "\n",
            " Enter Quill and the Grapes.\n",
            "\n",
            "QUILL.\n",
            "There is a part in her that was once a sign of love\n",
            "That she would not be married to the man who\n",
            "Shall be known as her husband.\n",
            "\n",
            "GRAHAM.\n",
            "Her husband?\n",
            "\n",
            "QUILL.\n",
            "She is to be married to a man that\n",
            "Shall be known as her husband.\n",
            "\n",
            "GRAHAM.\n",
            "No, she will not be married to her husband.\n",
            "\n",
            "QUILL.\n",
            "He hath had a wife of his,\n",
            "And I have had a wife of mine,\n",
            "And I have married her to a man\n",
            "Shall be known as her husband.\n",
            "\n",
            "GRAHAM.\n",
            "His husband?\n",
            "\n",
            "QUILL.\n",
            "He hath had a wife of his,\n",
            "And I have had a wife of mine,\n",
            "\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "\n",
            "CLOWN.\n",
            "Why, then, why, what a scene is this?\n",
            "\n",
            "JULIA.\n",
            "I know not how to tell.\n",
            "\n",
            "CLOWN.\n",
            "He that hath seen this livery,\n",
            "He knows not how to tell.\n",
            "\n",
            "JULIA.\n",
            "There is the grave, and there is the grave.\n",
            "\n",
            "CLOWN.\n",
            "And there is the grave, and there is the grave.\n",
            "\n",
            "JULIA.\n",
            "O, dammit!\n",
            "\n",
            "CLOWN.\n",
            "There is not a grave of all this,\n",
            "But there are graves of all the rest.\n",
            "\n",
            "JULIA.\n",
            "If the grave were as crimson as such a thing,\n",
            "For it is holy in crimson, I say,\n",
            "It would not be so bloody a mass.\n",
            "\n",
            "CLOWN.\n",
            "But the grave is not so blood-stained,\n",
            "It is blood-stained as such a thing.\n",
            "\n",
            "JULIA.\n",
            "O\n",
            "====================\n",
            "ROMEO.\n",
            "He jests at scars that never felt a wound.\n",
            "\n",
            " Juliet appears above at a window.\n",
            "\n",
            "But soft, what light through yonder window breaks?\n",
            "It is the east, and Juliet is the sun!\n",
            "Arise fair sun and kill the envious moon,\n",
            "Who is already sick and pale with grief,\n",
            "That thou her maid art far more fair than she.\n",
            "What, what cold, what frost, what cold,\n",
            "What cold, what cold, what cold, what cold,\n",
            "What cold, what cold, what cold, what cold,                                                                                                                                                                   \n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490a4648-d973-4675-cf9a-7a48c16fd736"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LORD FITZWATER:\n",
            "By heaven, I will not stand by while thy words are bandied about.\n",
            "\n",
            "RICHARD:\n",
            "Tyrannical times make good the sore; and\n",
            "thy old quarrel oft again becomes a joy.\n",
            "\n",
            "WARWICK:\n",
            "So will I no longer stand by while he prove a fool.\n",
            "\n",
            "KING RICHARD III:\n",
            "Now Joan's a torch to keep on the king;\n",
            "And his heir his mother's flame.\n",
            "\n",
            "WARWICK:\n",
            "Nay, my eyes will soon wither and die out;\n",
            "For I will be the man, as the flower is the fruit.\n",
            "\n",
            "KING RICHARD III:\n",
            "The more fool you by so much, the more light you allow.\n",
            "\n",
            "RICHARD:\n",
            "I am too heavy a sleeper to rest my meaning;\n",
            "But by the heavy fancy of my state\n",
            "I have lighten'd the minstrels by soaring high.\n",
            "\n",
            "KING RICHARD III:\n",
            "Ay, but I bethink me of no other but this:\n",
            "Come, let's away; the tediousness end.\n",
            "\n",
            "RICHARD:\n",
            "How now! what news with you?\n",
            "\n",
            "====================\n",
            "LORD ROSS:\n",
            "Yes, and by many, many\n",
            "And many more, many, many;\n",
            "And where I seem to stand, you may say,\n",
            "My stand, or your bosom is changed,\n",
            "My lord, my substitute, my sovereign.\n",
            "\n",
            "CLIFFORD:\n",
            "Then, good my lord,\n",
            "Look to the approach of night:\n",
            "Go, then, to the north-east; south-west, go.\n",
            "\n",
            "WARWICK:\n",
            "Get on, my lord; quickly I'll withdraw.\n",
            "\n",
            "YORK:\n",
            "The county of Lancaster shall be the field.\n",
            "\n",
            "MONTAGUE:\n",
            "And get ourself in, my lord; on the other hand,\n",
            "Go, with us, to the Duke of York's;\n",
            "there will I rest pat, and there awake I\n",
            "dine; that I may willingly accept and wear\n",
            "The regal crown.\n",
            "\n",
            "KING RICHARD III:\n",
            "Wine and ale? what's their brand?\n",
            "\n",
            "MONTAGUE:\n",
            "Theirs is their country's money: but they\n",
            "wear costly regalia; and we, being so rich\n",
            "in ale and straw, neither in men's nor women's,\n",
            "T\n",
            "====================\n",
            "LORD STANLEY:\n",
            "Is it thus that thou, Lord Hastings, art thus dealt,\n",
            "Under the title of a man?\n",
            "\n",
            "WARWICK:\n",
            "Why, am I thus dealt out to thee, Lord Hastings?\n",
            "\n",
            "KING RICHARD III:\n",
            "Thou art thus dealt out to me, Lord Hastings:\n",
            "Being so usurp'd, thou art but a man.\n",
            "But is it not plain sailing?\n",
            "\n",
            "WARWICK:\n",
            "Why, am I thus dealt out to thee, Lord Hastings?\n",
            "\n",
            "KING RICHARD III:\n",
            "Thou art thus dealt out to me, Lord Hastings:\n",
            "Being so usurp'd, thou art but a man.\n",
            "But is it not plain sailing?\n",
            "\n",
            "WARWICK:\n",
            "Why then, I puff my heart to the wind,\n",
            "And puff my chest to the blowing sea.\n",
            "\n",
            "KING RICHARD III:\n",
            "Why then, I speak aloud, I heart\n",
            "To thee, sweet Warwick, my life, thy death,\n",
            "Three fair English words and three fair hearts.\n",
            "\n",
            "WARWICK:\n",
            "What words shall I begin and end this merry dance?\n",
            "\n",
            "KING RICHARD III:\n",
            "As as as as\n",
            "====================\n",
            "LORD FITZWATER:\n",
            "love thy kinsman, for thyself\n",
            "I prize mine own perdition over thine.\n",
            "\n",
            "LORD FITZWATER:\n",
            "if thou match, and wilt prove mine own,\n",
            "Go chase after him, and he shall love thee well.\n",
            "\n",
            "LORD FITZWATER:\n",
            "if thou darest, I'll take him for my brother,\n",
            "Both love and truth, truth and falsehood.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "So thrive I in my profession as thou\n",
            "Can best advantage my skill! my brother\n",
            "Shalt be bring him to my cell, and there I\n",
            "Take him under my wing, to my profound environ\n",
            "Where serpents and marauding bats may perforce.\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "How well I use this device! how well\n",
            "This prince may my care and my fortunes advance\n",
            "Upon my son! my dear-loved and respected queen and father\n",
            "And all the true friends of true York!\n",
            "What cares I for London, troth o' the morn?\n",
            "And shall I live in love with Crosby and Vaughan?\n",
            "Is love a thing sworn or\n",
            "====================\n",
            "LORD FITZWATER:\n",
            "Away with her!\n",
            "\n",
            "Second Murderer:\n",
            "How now! where have you been?\n",
            "\n",
            "Second Murderer:\n",
            "I have been sent for to the county.\n",
            "\n",
            "First Murderer:\n",
            "I pray you, do not call my master, now dead.\n",
            "\n",
            "Second Murderer:\n",
            "Now, Yorktown, I pray you, stay by me.\n",
            "\n",
            "First Murderer:\n",
            "You are a pair of robbers that will rob our store.\n",
            "\n",
            "Second Murderer:\n",
            "Why, Yorktown, I know thee well; and thou, knowing our need,\n",
            "Strives to be our stead broker.\n",
            "\n",
            "First Murderer:\n",
            "Well; what then? whither then comes the store to be ready?\n",
            "\n",
            "Second Murderer:\n",
            "Yea, then, which, Yorktown, as soon as now, we have.\n",
            "\n",
            "First Murderer:\n",
            "Strives you now, then arrives Yorktown, to rob our store?\n",
            "\n",
            "Second Murderer:\n",
            "Unhappily, I fear, for we will not be ransomed in that instance.\n",
            "\n",
            "First Murderer:\n",
            "Well, let it be known to Stanley that we\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}